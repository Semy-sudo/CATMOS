{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "고양이종분류_실시간.ipynb",
      "provenance": [],
      "mount_file_id": "1xOizhnmCrKktoAsKXUXHcvJJnMg8DaMz",
      "authorship_tag": "ABX9TyPovbIeMSFsac4szs6NaXrh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Semy-sudo/CATMOS/blob/yein/%EA%B3%A0%EC%96%91%EC%9D%B4%EC%A2%85%EB%B6%84%EB%A5%98_%EC%8B%A4%EC%8B%9C%EA%B0%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJmaAp6ZCOef",
        "colab_type": "code",
        "outputId": "f9a7c755-8ff2-4f24-fb4a-56e7a9c7ea23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!git clone https://github.com/subhamroy021/Facial-Recognition.git "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Facial-Recognition'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "Unpacking objects:   6% (1/15)   \rUnpacking objects:  13% (2/15)   \rUnpacking objects:  20% (3/15)   \rUnpacking objects:  26% (4/15)   \rUnpacking objects:  33% (5/15)   \rUnpacking objects:  40% (6/15)   \rUnpacking objects:  46% (7/15)   \rUnpacking objects:  53% (8/15)   \rUnpacking objects:  60% (9/15)   \rUnpacking objects:  66% (10/15)   \rUnpacking objects:  73% (11/15)   \rUnpacking objects:  80% (12/15)   \rremote: Total 15 (delta 0), reused 0 (delta 0), pack-reused 15\u001b[K\n",
            "Unpacking objects:  86% (13/15)   \rUnpacking objects:  93% (14/15)   \rUnpacking objects: 100% (15/15)   \rUnpacking objects: 100% (15/15), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5EOUzuC5NGz",
        "colab_type": "code",
        "outputId": "19adbfa3-0ddb-47d5-bd72-93f21ced124f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!git clone https://github.com/opencv/opencv/tree/master/data/haarcascades"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'haarcascades'...\n",
            "fatal: repository 'https://github.com/opencv/opencv/tree/master/data/haarcascades/' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQqquNrpeaTV",
        "colab_type": "code",
        "outputId": "53a4c01e-3fbc-4d9a-c4f6-e417fb6b6b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_x1Rg6t8QjE",
        "colab_type": "code",
        "outputId": "9711e24e-62e3-4c01-c12b-18a7006c13e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import os\n",
        "print(os.getcwd()) #현재 경로보기"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muUh4ahQ82yf",
        "colab_type": "code",
        "outputId": "13931a4b-f159-40d8-cc16-597cf0849250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#특정 파일 경로 보기\n",
        "#print(os.chdir('Cats dataset'))\n",
        "path = \"./\"\n",
        "file_list = os.listdir(path)\n",
        "\n",
        "print (\"file_list: {}\".format(file_list))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_list: ['.config', 'Facial-Recognition', 'gdrive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBSdazaR9Juo",
        "colab_type": "code",
        "outputId": "7d0df70c-8b61-4870-f4eb-42ef966a6cd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(os.path.abspath(\"Facial-Recognition\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Facial-Recognition\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWJq1jko9mfn",
        "colab_type": "code",
        "outputId": "c43f94ce-043b-44d1-ddfc-5040ab5b2a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(os.path.abspath(\"haarcascade_frontalcatface.xml\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/haarcascade_frontalcatface.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RhJ0SxK9WmF",
        "colab_type": "code",
        "outputId": "86b04459-20d7-4918-ee68-f7c9cc0e408e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "#파일이 존재하는지 확인\n",
        "print(os.path.exists(\"sample_data\"))\n",
        "print(os.path.exists(\"Facial-Recognition\"))\n",
        "print(os.path.exists(\"gdive/My Drive/Colab Notebooks/Facial-Recognition/haarcascade_frontalcatface.xml\"))\n",
        "print(os.path.exists(\"haarcascade_frontalcatface.xml\"))\n",
        "print(os.path.exists(\"haarcascade_eye.xml\"))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "False\n",
            "False\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raBMnOzSP0rC",
        "colab_type": "code",
        "outputId": "fc1be964-58fc-416c-f333-7e67b295a46f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "ls -ltr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ls: cannot access 'gdrive': Transport endpoint is not connected\n",
            "total 2896\n",
            "d????????? ? ?    ?          ?            ? \u001b[0m\u001b[01;34mgdrive\u001b[0m/\n",
            "drwxr-xr-x 1 root root    4096 May 13 16:29 \u001b[01;34msample_data\u001b[0m/\n",
            "drwxr-xr-x 3 root root    4096 May 23 13:51 \u001b[01;34mFacial-Recognition\u001b[0m/\n",
            "drwx------ 4 root root    4096 May 23 14:37 \u001b[01;34mdrive\u001b[0m/\n",
            "-rw-r--r-- 1 root root 2952722 May 23 15:06 cat.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5CeVrd42-T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import webbrowser \n",
        "\n",
        "\n",
        "#얼국 인식용 xml 파일 \n",
        "#/content/drive/My Drive/Colab Notebooks\n",
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalcatface.xml') #얼굴 영역인지 판단"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR3_JAoQGRub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#전체 사진에서 얼굴 부위만 잘라 리턴\n",
        "def face_extractor(img):\n",
        "    #src = cv2.imread(\"gdrive/My Drive/Colab Notebooks/faces/user1.jpg\", cv2.IMREAD_COLOR)\n",
        "    #흑백처리 \n",
        "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #원본이미지, 색상변환칼러\n",
        "    #얼굴 찾기 \n",
        "    faces = face_classifier.detectMultiScale(gray,1.3,5) #gray 입혀 얼굴검출\n",
        "    #찾은 얼굴이 없으면 None으로 리턴 \n",
        "    if faces is():\n",
        "        return None\n",
        "        \n",
        "    #얼굴들이 있으면 \n",
        "    for(x,y,w,h) in faces:\n",
        "        #해당 얼굴 크기만큼 cropped_face에 잘라 넣기 \n",
        "        #근데... 얼굴이 2개 이상 감지되면??\n",
        "        #가장 마지막의 얼굴만 남을 듯\n",
        "        cropped_face = img[y:y+h, x:x+w]\n",
        "    #cropped_face 리턴 \n",
        "    return cropped_face\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t7vmDJd4k0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def showVideo():\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(\"cat.mp4\")\n",
        "        #cap=cv2.VideoCapture(0) #비디오 캡쳐 객체 생성\n",
        "        print('카메라를 구동합니다.')\n",
        "        #a = cap.isOpened()\n",
        "        #print(a)\n",
        "        #b = cap.open()\n",
        "        #print(b)\n",
        "    except:\n",
        "        print('카메라 구동 실패')\n",
        "        return\n",
        "\n",
        "    cap.set(3, 480)\n",
        "    cap.set(4, 320)\n",
        "\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read() \n",
        "        #비디오의 한 프레임씩 읽습니다. \n",
        "        #제대로 프레임을 읽으면 ret값이 True, 실패하면 False가 나타납니다. fram에 읽은 프레임이 나옵니다\n",
        "       \n",
        "        \n",
        "\n",
        "        if not ret:\n",
        "          print('비디오 읽기 오류')\n",
        "          break\n",
        "\n",
        "        gray = cv2.cv2Color(frame, cv2.COLOR_BGR2GRAY)\n",
        "        cv2.imshow('video',gray)\n",
        "\n",
        "        k = cv2.waitKey(1) & 0xFF\n",
        "        if k == 27:\n",
        "          break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "      \n",
        " \n",
        "#showVideo()\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-E8E3eWsQsj",
        "colab_type": "code",
        "outputId": "8748191d-32e9-43b3-c227-c331082d1590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "\n",
        "##1.모델 트레이닝 시키기\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "data_path = 'drive/My Drive/Colab Notebooks/faces/'\n",
        "#faces폴더에 있는 파일 리스트 얻기 \n",
        "onlyfiles = [f for f in listdir(data_path) if isfile(join(data_path,f))]\n",
        "#데이터와 매칭될 라벨 변수 \n",
        "Training_Data, Labels = [], []\n",
        "#파일 개수 만큼 루프 \n",
        "for i, files in enumerate(onlyfiles):    \n",
        "    image_path = data_path + onlyfiles[i]\n",
        "    #이미지 불러오기 \n",
        "    images = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    #이미지 파일이 아니거나 못 읽어 왔다면 무시\n",
        "    if images is None:\n",
        "        continue    \n",
        "    #Training_Data 리스트에 이미지를 바이트 배열로 추가 \n",
        "    Training_Data.append(np.asarray(images, dtype=np.uint8))\n",
        "    #Labels 리스트엔 카운트 번호 추가 \n",
        "    Labels.append(i)\n",
        "\n",
        "#훈련할 데이터가 없다면 종료.\n",
        "if len(Labels) == 0:\n",
        "    print(\"There is no data to train.\")\n",
        "    exit()\n",
        "\n",
        "#Labels를 32비트 정수로 변환\n",
        "Labels = np.asarray(Labels, dtype=np.int32)\n",
        "#모델 생성 \n",
        "model = cv2.face.LBPHFaceRecognizer_create()\n",
        "#학습 시작 \n",
        "model.train(np.asarray(Training_Data), np.asarray(Labels))\n",
        "print(\"Model Training Complete!!!!!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Training Complete!!!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AcxnBdGKM4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') # 이 xml 파일이 업로드가 안됨 ㅜㅜㅜ\n",
        "\n",
        "def face_detector(img, size = 0.5):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_classifier.detectMultiScale(gray,1.3,5) #gray 입혀서 얼굴 검출해주는 함수\n",
        "    if faces is():\n",
        "        return img,[]\n",
        "    for(x,y,w,h) in faces:\n",
        "        cv2.rectangle(img, (x,y),(x+w,y+h),(0,255,255),2)\n",
        "        roi = img[y:y+h, x:x+w]\n",
        "        roi = cv2.resize(roi, (200,200))\n",
        "    return img,roi   #검출된 좌표에 사각 박스 그리고(img), 검출된 부위를 잘라(roi) 전달"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx1nsAjP29Xj",
        "colab_type": "code",
        "outputId": "17143095-bc2e-454c-d2f9-97ed3b99b970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "#카메라 열기 \n",
        "cap = cv2.VideoCapture('cat.mp4') #비디오캡처함수 객체 cap\n",
        "\n",
        "while True:\n",
        "    #카메라로 부터 사진 한장 읽기 \n",
        "    ret, frame = cap.read()\n",
        "    # 얼굴 검출 시도 \n",
        "    image, face = face_detector(frame) #앞서 정의한 face_detector(얼굴 검출기)\n",
        "    try:\n",
        "        #검출된 사진을 흑백으로 변환 \n",
        "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
        "        #위에서 학습한 모델로 예측시도\n",
        "        result = model.predict(face)\n",
        "        #result[1]은 신뢰도이고 0에 가까울수록 자신과 같다는 뜻이다. \n",
        "        if result[1] < 500:\n",
        "            #????? 어쨋든 0~100표시하려고 한듯 \n",
        "            confidence = int(100*(1-(result[1])/300))\n",
        "            # 유사도 화면에 표시 \n",
        "            display_string = str(confidence)+'% Confidence it is user'\n",
        "        cv2.putText(image,display_string,(100,120), cv2.FONT_HERSHEY_COMPLEX,1,(250,120,255),2)\n",
        "        #75 보다 크면 동일 인물로 간주해 UnLocked! \n",
        "        if confidence > 75:\n",
        "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.imshow('Face Cropper', image)\n",
        "        else:\n",
        "           #75 이하면 타인.. Locked!!! \n",
        "            cv2.putText(image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
        "            cv2.imshow('Face Cropper', image)\n",
        "    except:\n",
        "        #얼굴 검출 안됨 \n",
        "        cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
        "        cv2.imshow('Face Cropper', image)\n",
        "        pass\n",
        "    if cv2.waitKey(1)==13:\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-dbadf756dc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 얼굴 검출 시도\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#검출된 사진을 흑백으로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-9d1104c46cd4>\u001b[0m in \u001b[0;36mface_detector\u001b[0;34m(img, size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#gray 입혀서 얼굴 검출해주는 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/objdetect/src/cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'detectMultiScale'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBmKNGsxLPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}