{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 멀티라벨 분류 **\n",
    "\n",
    "비행기, 불상, 나비, 게 4가지의 이미지를 분류해본다\n",
    "\n",
    "기본적인 방법은 단일 이미지 분류와 같다. 대신, 다중 이미지 분류이기 때문에 카테고리의 변화가 있다.\n",
    "\n",
    "그리고 단일 보다 데이터셋이 현저히 부족하다. 이는 데이터셋을 잘 못모은 내 잘못이다.\n",
    "\n",
    "미리 양해를 구한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bombay  파일 길이 :  100\n",
      "Bombay  :  ./catdateset/train/Bombay\\Bombay (1).jpg\n",
      "Persian  파일 길이 :  100\n",
      "Persian  :  ./catdateset/train/Persian\\persian1.jpg\n",
      "Russianblue  파일 길이 :  100\n",
      "Russianblue  :  ./catdateset/train/Russianblue\\Russianblue (1).jpg\n",
      "Siberia  파일 길이 :  98\n",
      "Siberia  :  ./catdateset/train/Siberia\\Siberia.jpg\n",
      "ok 398\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./catdateset/train\"\n",
    "categories = [\"Bombay\", \"Persian\", \"Russianblue\", \"Siberia\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./numpy_data/m_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 numpy 데이터를 불러온다. 저것을 가지고 학습!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(298, 64, 64, 3)\n",
      "298\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('./numpy_data/m_image_data.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"Bombay\", \"Persian\", \"Russianblue\", \"Siberia\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 4,214,980\n",
      "Trainable params: 4,214,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "298/298 [==============================] - 5s 18ms/step - loss: 0.4985 - accuracy: 0.7953 - val_loss: 0.7501 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.75044 to 0.75013, saving model to ./model/multi_img_classification.model\n",
      "Epoch 2/50\n",
      "298/298 [==============================] - 4s 15ms/step - loss: 0.4070 - accuracy: 0.8591 - val_loss: 0.7704 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.75013\n",
      "Epoch 3/50\n",
      "298/298 [==============================] - 4s 14ms/step - loss: 0.3634 - accuracy: 0.8658 - val_loss: 0.8132 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.75013\n",
      "Epoch 4/50\n",
      "298/298 [==============================] - 4s 14ms/step - loss: 0.3868 - accuracy: 0.8557 - val_loss: 0.8442 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.75013\n",
      "Epoch 5/50\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.3277 - accuracy: 0.9027 - val_loss: 0.8102 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.75013\n",
      "Epoch 6/50\n",
      "298/298 [==============================] - 4s 15ms/step - loss: 0.2647 - accuracy: 0.9161 - val_loss: 0.8367 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.75013\n",
      "Epoch 7/50\n",
      "298/298 [==============================] - 5s 16ms/step - loss: 0.2666 - accuracy: 0.8993 - val_loss: 0.8753 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.75013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#데이터셋이 적어서 validation을 그냥 test 데이터로 했습니다. \n",
    "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 3ms/step\n",
      "정확도 : 0.6600\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_5_input to have 4 dimensions, but got array with shape (0, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-0690293411ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./model/multi_img_classification.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"{0:0.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\ANA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\ANA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\ANA\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_5_input to have 4 dimensions, but got array with shape (0, 1)"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "caltech_dir = \"./catdateset/train\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "\n",
    "X = np.array(X)\n",
    "model = load_model('./model/multi_img_classification.model')\n",
    "\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"Bombay\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"Persian\"\n",
    "    elif pre_ans == 2: pre_ans_str = \"Russianblue\"\n",
    "    else: pre_ans_str = \"Siberia\"\n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
    "    # 이걸 한 것은 _4.py에.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비록 데이터가 적지만 그래도 나름 학습이 잘 되었습니다.\n",
    "\n",
    "하지만 **validation data와 test data가 나뉘어져 있지 않습니다.**\n",
    "\n",
    "이는 매우 위험한 시도입니다. 왜냐하면 검증 단계에서 테스트 데이터를 사용했는데 또 마지막에 정확도 검출 시 test_data를 사용합니다.\n",
    "\n",
    "데이터가 충분하다면 이런짓은 하지 않는게 좋습니다!\n",
    "\n",
    "하지만 새로운 데이터에 대한 예측은 그래도 잘 하는군요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
