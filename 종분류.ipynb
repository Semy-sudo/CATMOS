{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "종분류.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMypFlAvOgAsWP+EQtByL7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Semy-sudo/CATMOS/blob/master/%EC%A2%85%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvpnOv35Y6bp",
        "colab_type": "code",
        "outputId": "978d3263-f5ec-41c3-f61f-ddd184a58886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#구글 드라이브로 부터 파일 가져오기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPSHzWlchWre",
        "colab_type": "code",
        "outputId": "7c12fb2f-c38e-4fc5-a81f-c1757e9f666f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#텐서 버전 확인\n",
        "!pip show tensorflow\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0rc4\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorboard, tensorflow-estimator, termcolor, wheel, google-pasta, grpcio, h5py, scipy, astunparse, absl-py, numpy, opt-einsum, protobuf, wrapt, six, gast, keras-preprocessing\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "749WsV0YjFqY",
        "colab_type": "code",
        "outputId": "7b67f642-e1a9-4131-eef9-02246440747c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 30kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.4)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed tensorflow-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQsqmqfZjKpp",
        "colab_type": "code",
        "outputId": "2a809650-53fe-4931-d56d-3deaa7907ac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "source": [
        "!pip install tensorflow==1.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 82kB/s \n",
            "\u001b[?25hCollecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.12.0)\n",
            "Collecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Collecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.18.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.0.1)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 19.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (46.1.3)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136299 sha256=0e620a7718908559fa956bfa0199e64cf039a0553760e112faca525e0232f4c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=193549df15aa99544c87a6d4f9d7bcf47f39172a095bdbbfa1ca869db82c0d1a\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mERROR: tensorboard 2.2.1 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: html5lib, bleach, backports.weakref, markdown, tensorflow\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "  Found existing installation: Markdown 3.2.1\n",
            "    Uninstalling Markdown-3.2.1:\n",
            "      Successfully uninstalled Markdown-3.2.1\n",
            "  Found existing installation: tensorflow 2.2.0rc4\n",
            "    Uninstalling tensorflow-2.2.0rc4:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc4\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVfXb52HjK0f",
        "colab_type": "code",
        "outputId": "b7bdaed6-a149-43c8-841c-d647a1639732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 144429 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9d7ab_cl05N",
        "colab_type": "code",
        "outputId": "866fe4bf-6a9c-4ee3-9626-c7df46313647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "!pip uninstall tensorflow\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.2.0rc4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow-2.2.0rc4.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "y\n",
            "y\n",
            "  Successfully uninstalled tensorflow-2.2.0rc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9cq1DJCmJPK",
        "colab_type": "code",
        "outputId": "fcd82948-bc1e-44db-fa58-7af460a8ad03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        }
      },
      "source": [
        "!pip install tensorflow==1.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/55/7995cc1e9e60fa37ea90e6777d832e75026fde5c6109215d892aaff2e9b7/tensorflow-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (35.0MB)\n",
            "\u001b[K     |████████████████████████████████| 35.0MB 94kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (0.34.2)\n",
            "Collecting markdown==2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/99/288a81a38526a42c98b5b9832c6e339ca8d5dd38b19a53abfac7c8037c7f/Markdown-2.2.0.tar.gz (236kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 61.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (3.10.0)\n",
            "Collecting html5lib==0.9999999\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.18.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.12.0)\n",
            "Collecting backports.weakref==1.0rc1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/f7/ae34b6818b603e264f26fe7db2bd07850ce331ce2fde74b266d61f4a2d87/backports.weakref-1.0rc1-py3-none-any.whl\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.2) (1.0.1)\n",
            "Collecting bleach==1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorflow==1.2) (46.1.3)\n",
            "Building wheels for collected packages: markdown, html5lib\n",
            "  Building wheel for markdown (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markdown: filename=Markdown-2.2.0-cp36-none-any.whl size=136290 sha256=394057bd2ab5bf6ce03e31e885731c1009d931551eb08a753a6dc9ea19c7c0d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/52/17/f0af18e3e0ec6fa60b361ffed15b4c3468f6f3bcdb87fbe079\n",
            "  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=2c603240e83267b0e397f85106d10fdacf7162abfc72a2a4d50750ba84a89d77\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
            "Successfully built markdown html5lib\n",
            "\u001b[31mERROR: tensorboard 2.2.1 has requirement markdown>=2.6.8, but you'll have markdown 2.2.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: markdown, html5lib, backports.weakref, bleach, tensorflow\n",
            "  Found existing installation: Markdown 3.2.1\n",
            "    Uninstalling Markdown-3.2.1:\n",
            "      Successfully uninstalled Markdown-3.2.1\n",
            "  Found existing installation: html5lib 1.0.1\n",
            "    Uninstalling html5lib-1.0.1:\n",
            "      Successfully uninstalled html5lib-1.0.1\n",
            "  Found existing installation: bleach 3.1.5\n",
            "    Uninstalling bleach-3.1.5:\n",
            "      Successfully uninstalled bleach-3.1.5\n",
            "Successfully installed backports.weakref-1.0rc1 bleach-1.5.0 html5lib-0.9999999 markdown-2.2.0 tensorflow-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIptqBzlmS23",
        "colab_type": "code",
        "outputId": "0c12ef94-56ed-41bb-9490-87066d53c834",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.2.0\n",
            "Summary: TensorFlow helps the tensors flow\n",
            "Home-page: http://tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: opensource@google.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: backports.weakref, bleach, wheel, six, numpy, protobuf, html5lib, markdown, werkzeug\n",
            "Required-by: fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pGbUIT1nvhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "20e86fa9-da65-43ad-aec7-178ef1271b87"
      },
      "source": [
        "#구글 드라이브로 부터 파일 가져오기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCbJr_oYlHU_",
        "colab_type": "code",
        "outputId": "c15a452e-2e60-4442-df6c-41e6ff4689d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "caltech_dir = \"/content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others/train\"\n",
        "categories = [\"러시안블루\", \"봄베이\", \"Persian\", \"Siberia\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for idx, cat in enumerate(categories):\n",
        "    \n",
        "    #one-hot 돌리기.\n",
        "    label = [0 for i in range(nb_classes)]\n",
        "    label[idx] = 1\n",
        "    \n",
        "    #cat = \"러시안블루\", \"봄베이\", \"Persian\", \"Siberia\" 중 하나\n",
        "    image_dir = caltech_dir + \"/\" + cat\n",
        "    files = glob.glob(image_dir+\"/*.jpg\")\n",
        "    print(cat, \" 파일 길이 : \", len(files))\n",
        "    for i, f in enumerate(files):\n",
        "        img = Image.open(f)\n",
        "        img = img.convert(\"RGB\")\n",
        "        img = img.resize((image_w, image_h))\n",
        "        data = np.asarray(img)\n",
        "\n",
        "        X.append(data)\n",
        "        y.append(label)\n",
        "\n",
        "        if i % 700 == 0:\n",
        "            print(cat, \" : \", f)\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "#1 0 0 0 이면 러시안블루\n",
        "#0 1 0 0 이면 봄베이 이런식\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "#경로에 train test data 를 multi_image_data 로 저장\n",
        "np.save(\"/content/drive/My Drive/Colab Notebooks/numpy_data/multi_image_data.npy\", xy)\n",
        "\n",
        "print(\"ok\", len(y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "러시안블루  파일 길이 :  100\n",
            "러시안블루  :  /content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others/train/러시안블루/러시안블루1.jpg\n",
            "봄베이  파일 길이 :  100\n",
            "봄베이  :  /content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others/train/봄베이/001.jpg\n",
            "Persian  파일 길이 :  100\n",
            "Persian  :  /content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others/train/Persian/persian1.jpg\n",
            "Siberia  파일 길이 :  99\n",
            "Siberia  :  /content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others/train/Siberia/Siberia.jpg\n",
            "ok 399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlOb9aCdll6g",
        "colab_type": "code",
        "outputId": "326dbaff-9f85-46ec-9366-a8f97bce0f24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "import os, glob, numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend.tensorflow_backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = tf.Session(config=config)\n",
        "\n",
        "X_train, X_test, y_train, y_test = np.load('.numpy_data/multi_image_data.npy')\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-dc3f3fbe308e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ24Kgd4VfKo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "b94039c4-aeea-4c7c-864f-ed38772c6693"
      },
      "source": [
        "X_train, X_test, y_train, y_test = np.load('/content/drive/My Drive/Colab Notebooks/numpy_data/multi_image_data.npy')\n",
        "print(X_train.shape)\n",
        "print(X_train.shape[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-43760755e16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/numpy_data/multi_image_data.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 453\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[1;32m    740\u001b[0m                              \"allow_pickle=False\")\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV9JalmhfRM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\"러시안블루\", \"봄베이\", \"Persian\", \"Siberia\"\n",
        "categories = [\"러시안블루\", \"봄베이\", \"Persian\", \"Siberia\"]\n",
        "nb_classes = len(categories)\n",
        "\n",
        "#일반화\n",
        "X_train = X_train.astype(float) / 255\n",
        "X_test = X_test.astype(float) / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaDHaKTo30eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with K.tf_ops.device('/device:GPU:0'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(nb_classes, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model_dir = './model'\n",
        "    \n",
        "    if not os.path.exists(model_dir):\n",
        "        os.mkdir(model_dir)\n",
        "    \n",
        "    model_path = model_dir + '/multi_img_classification.model'\n",
        "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVz-EV1g32uJ",
        "colab_type": "code",
        "outputId": "a90e5ccc-d368-4090-bb4b-744be33643ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               4194560   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 4,214,980\n",
            "Trainable params: 4,214,980\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gJrLBVA35wr",
        "colab_type": "code",
        "outputId": "ce6829c7-77ce-4fcd-e3e9-9365b7373448",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#데이터셋이 적어서 validation을 그냥 test 데이터로 했습니다. \n",
        "#데이터셋이 충분하시면 이렇게 하시지 마시고 validation_split=0.2 이렇게 하셔서 테스트 셋으로 나누시길 권장합니다.\n",
        "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 299 samples, validate on 100 samples\n",
            "Epoch 1/50\n",
            "299/299 [==============================] - 3s 10ms/step - loss: 1.9318 - accuracy: 0.3077 - val_loss: 1.3797 - val_accuracy: 0.3500\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.37972, saving model to ./model/multi_img_classification.model\n",
            "Epoch 2/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 1.3675 - accuracy: 0.3746 - val_loss: 1.3756 - val_accuracy: 0.3100\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.37972 to 1.37560, saving model to ./model/multi_img_classification.model\n",
            "Epoch 3/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 1.3511 - accuracy: 0.3344 - val_loss: 1.3581 - val_accuracy: 0.4600\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.37560 to 1.35807, saving model to ./model/multi_img_classification.model\n",
            "Epoch 4/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 1.2427 - accuracy: 0.4548 - val_loss: 1.2218 - val_accuracy: 0.4500\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.35807 to 1.22185, saving model to ./model/multi_img_classification.model\n",
            "Epoch 5/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.9999 - accuracy: 0.5351 - val_loss: 0.9796 - val_accuracy: 0.5700\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.22185 to 0.97959, saving model to ./model/multi_img_classification.model\n",
            "Epoch 6/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.8432 - accuracy: 0.6187 - val_loss: 0.9005 - val_accuracy: 0.6100\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.97959 to 0.90047, saving model to ./model/multi_img_classification.model\n",
            "Epoch 7/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.7528 - accuracy: 0.6890 - val_loss: 0.8544 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.90047 to 0.85435, saving model to ./model/multi_img_classification.model\n",
            "Epoch 8/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.6870 - accuracy: 0.7224 - val_loss: 0.8299 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.85435 to 0.82995, saving model to ./model/multi_img_classification.model\n",
            "Epoch 9/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.5758 - accuracy: 0.7659 - val_loss: 0.8299 - val_accuracy: 0.6200\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.82995 to 0.82988, saving model to ./model/multi_img_classification.model\n",
            "Epoch 10/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.5809 - accuracy: 0.7559 - val_loss: 0.8104 - val_accuracy: 0.6700\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.82988 to 0.81038, saving model to ./model/multi_img_classification.model\n",
            "Epoch 11/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.4967 - accuracy: 0.8227 - val_loss: 0.8095 - val_accuracy: 0.6500\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.81038 to 0.80947, saving model to ./model/multi_img_classification.model\n",
            "Epoch 12/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.4817 - accuracy: 0.8294 - val_loss: 0.7638 - val_accuracy: 0.7100\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.80947 to 0.76384, saving model to ./model/multi_img_classification.model\n",
            "Epoch 13/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.4304 - accuracy: 0.8595 - val_loss: 0.7468 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.76384 to 0.74680, saving model to ./model/multi_img_classification.model\n",
            "Epoch 14/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.3568 - accuracy: 0.8796 - val_loss: 0.7724 - val_accuracy: 0.7100\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.74680\n",
            "Epoch 15/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.2949 - accuracy: 0.8930 - val_loss: 0.8094 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.74680\n",
            "Epoch 16/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.2688 - accuracy: 0.8997 - val_loss: 0.8232 - val_accuracy: 0.6900\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.74680\n",
            "Epoch 17/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.2755 - accuracy: 0.9097 - val_loss: 0.8386 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.74680\n",
            "Epoch 18/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.2268 - accuracy: 0.9197 - val_loss: 0.8506 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.74680\n",
            "Epoch 19/50\n",
            "299/299 [==============================] - 2s 8ms/step - loss: 0.2328 - accuracy: 0.9231 - val_loss: 0.8692 - val_accuracy: 0.7200\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.74680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLD6i6eD37pk",
        "colab_type": "code",
        "outputId": "5d56faca-c3ae-494f-94eb-96504bd18049",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 2ms/step\n",
            "정확도 : 0.7200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGPIj7py4FLV",
        "colab_type": "code",
        "outputId": "10dff98f-c222-4c63-e425-47edd818ef84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "x_len = np.arange(len(y_loss))\n",
        "\n",
        "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
        "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
        "plt.legend()\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "#학습에 대한 오차< 검증용 오차"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_iZMN4d4Hw7",
        "colab_type": "code",
        "outputId": "fdb129a2-a711-47b0-fe63-916a6af48f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        }
      },
      "source": [
        "\n",
        "from PIL import Image\n",
        "import os, glob, numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "caltech_dir = \"/content/drive/My Drive/Colab Notebooks/model/multi_img_data/imgs_others_test\"\n",
        "image_w = 64\n",
        "image_h = 64\n",
        "\n",
        "pixels = image_h * image_w * 3\n",
        "\n",
        "X = []\n",
        "filenames = []\n",
        "files = glob.glob(caltech_dir+\"/*.*\")\n",
        "for i, f in enumerate(files):\n",
        "    img = Image.open(f)\n",
        "    img = img.convert(\"RGB\")\n",
        "    img = img.resize((image_w, image_h))\n",
        "    data = np.asarray(img)\n",
        "    filenames.append(f)\n",
        "    X.append(data)\n",
        "\n",
        "X = np.array(X)\n",
        "model = load_model('./model/multi_img_classification.model')\n",
        "\n",
        "prediction = model.predict(X)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "cnt = 0\n",
        "\n",
        "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
        "for i in prediction:\n",
        "    pre_ans = i.argmax()  # 예측 레이블\n",
        "    print(i)\n",
        "    print(pre_ans)\n",
        "    pre_ans_str = ''\n",
        "    # 순서 \"러시안블루\", \"봄베이\", \"Persian\", \"Siberia\"\n",
        "    if pre_ans == 0: pre_ans_str = \"러시안블루\"\n",
        "    elif pre_ans == 1: pre_ans_str = \"봄베이\"\n",
        "    elif pre_ans == 2: pre_ans_str = \"Persian\"\n",
        "    else: pre_ans_str = \"Siberia\"\n",
        "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
        "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "    if i[3] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[1]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
        "    cnt += 1\n",
        "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
        "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다.\n",
        "    # 이걸 한 것은 _4.py에."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.000 0.000 0.000 0.000]\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-57987ddef189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpre_ans\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpre_ans_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Persian\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpre_ans_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Siberia\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"해당 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"이미지는 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpre_ans_str\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"로 추정됩니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"해당 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"이미지는 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpre_ans_str\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"으로 추정됩니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"해당 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\\\\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"이미지는 \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpre_ans_str\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"로 추정됩니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKnZ4RZ88AB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}